{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segmentation_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "waU9EEl5fkCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from glob import glob\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "\n",
        "\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )   \n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class=2):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.dconv_down1 = double_conv(3, 64)\n",
        "        self.dconv_down2 = double_conv(64, 128)\n",
        "        self.dconv_down3 = double_conv(128, 256)\n",
        "        self.dconv_down4 = double_conv(256, 512)        \n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
        "        \n",
        "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
        "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
        "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
        "        \n",
        "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.dconv_down2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        \n",
        "        conv3 = self.dconv_down3(x)\n",
        "        x = self.maxpool(conv3)   \n",
        "        \n",
        "        x = self.dconv_down4(x)\n",
        "        \n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        \n",
        "        x = self.dconv_up3(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv2], dim=1)       \n",
        "\n",
        "        x = self.dconv_up2(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv1], dim=1)   \n",
        "        \n",
        "        x = self.dconv_up1(x)\n",
        "        \n",
        "        out = self.conv_last(x)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrWdqc8oiXtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transform = transforms.Compose([\n",
        "        #transforms.RandomSizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "class image_seg(Dataset):\n",
        "    def __init__(self, data_dir='' ,transform=data_transform):\n",
        "        self.transform = data_transform\n",
        "        self.dirs =glob(data_dir) #read all images at onece\n",
        "    def __len__(self):\n",
        "        return len(self.dirs)\n",
        "    def __getitem__(self, idx):\n",
        "        input = Image.open(self.dirs[idx])\n",
        "        filename = os.path.basename(self.dirs[idx])\n",
        "        common_dir = os.path.dirname(os.path.dirname(self.dirs[idx]))\n",
        "        #ignore the last 4 digits in the file name [:-4] tiff\n",
        "        label_dir = common_dir +'/masks/'+filename[:-4] + 'png' \n",
        "        label = Image.open(label_dir).convert('L')\n",
        "        input = input.resize((224,224), Image.LINEAR)\n",
        "        input = np.array(input).transpose(2,0,1) #batch size first\n",
        "        label = label.resize((224,224), Image.NEAREST)\n",
        "\n",
        "        label = np.array(label)\n",
        "        label[label==255] = 1\n",
        "        label = torch.from_numpy(label).long()\n",
        "        input = torch.from_numpy(input).float()\n",
        "        return input, label\n",
        "\n",
        "Dataset_obj_train = image_seg(data_dir ='drive/My Drive/Dataset/Amazon_Forest/Training/images/**.tiff' ,transform=data_transform)\n",
        "trainloader = DataLoader(Dataset_obj_train, batch_size=4,shuffle=True, num_workers=2)\n",
        "\n",
        "Dataset_obj_valid = image_seg(data_dir ='drive/My Drive/Dataset/Amazon_Forest/Validation/images/**.tiff',transform=data_transform)\n",
        "validloader = DataLoader(Dataset_obj_valid, batch_size=4,shuffle=False, num_workers=2)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6jBpm8-lMtf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "880ec241-63c6-4361-e01d-1aa1e0f4e3ad"
      },
      "source": [
        "class image_seg_test(Dataset):\n",
        "    def __init__(self, data_dir='' ,transform=data_transform):\n",
        "        self.transform = data_transform\n",
        "        self.dirs =glob(data_dir)\n",
        "    def __len__(self):\n",
        "        return len(self.dirs)\n",
        "    def __getitem__(self, idx):\n",
        "        input = Image.open(self.dirs[idx])\n",
        "        filename = os.path.basename(self.dirs[idx])\n",
        "        common_dir = os.path.dirname(os.path.dirname(self.dirs[idx]))\n",
        "        input = input.resize((224,224), Image.LINEAR)\n",
        "        input = np.array(input).transpose(2,0,1)\n",
        "        input = torch.from_numpy(input).float()\n",
        "        return input, filename[:-4]\n",
        "\n",
        "Dataset_obj_test = image_seg_test(data_dir ='drive/My Drive/Dataset/Amazon_Forest/Test/**.tiff',transform=data_transform)\n",
        "testloader = DataLoader(Dataset_obj_test, batch_size=2,shuffle=False, num_workers=2)\n",
        "print(len(Dataset_obj_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OLU8EQShobu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "838e1fd5-fcb4-46be-ff50-557dadb0f620"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "net  = UNet(n_class=2)\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "net.to(device)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_epoch = 0\n",
        "best_acc = 0\n",
        "for epoch in range(50):\n",
        "    totoal_loss = 0\n",
        "    net.train()\n",
        "    for inputs,labels in trainloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = net(inputs)\n",
        "        loss = loss_function(logits,labels)\n",
        "        totoal_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "        \n",
        "\n",
        "    print (f'Epoch: {epoch+1:02} |Loss:{totoal_loss/len(trainloader)}')\n",
        "\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs,labels in validloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)  \n",
        "            logits = net(inputs)\n",
        "            loss = loss_function(logits,labels)\n",
        "            \n",
        "\n",
        "        if loss < best_loss:\n",
        "            best_loss = loss\n",
        "            best_epoch = epoch\n",
        "            torch.save(net.state_dict(), 'best_model.pt')\n",
        "            \n",
        "        print(\"curr_val_loss:\",loss.item(), \"epoch:\", epoch+1, \"best_loss\",best_loss.item(),\"best_epoch\",best_epoch)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 |Loss:0.8186461701989174\n",
            "curr_val_loss: 0.5211305022239685 epoch: 1 best_loss 0.5211305022239685 best_epoch 0\n",
            "Epoch: 02 |Loss:0.4220226816833019\n",
            "curr_val_loss: 0.2250683605670929 epoch: 2 best_loss 0.2250683605670929 best_epoch 1\n",
            "Epoch: 03 |Loss:0.24862528964877129\n",
            "curr_val_loss: 0.3878239095211029 epoch: 3 best_loss 0.2250683605670929 best_epoch 1\n",
            "Epoch: 04 |Loss:0.2646574564278126\n",
            "curr_val_loss: 0.2122773379087448 epoch: 4 best_loss 0.2122773379087448 best_epoch 3\n",
            "Epoch: 05 |Loss:0.24206285551190376\n",
            "curr_val_loss: 0.19166700541973114 epoch: 5 best_loss 0.19166700541973114 best_epoch 4\n",
            "Epoch: 06 |Loss:0.20249907858669758\n",
            "curr_val_loss: 0.1904958188533783 epoch: 6 best_loss 0.1904958188533783 best_epoch 5\n",
            "Epoch: 07 |Loss:0.21933837048709393\n",
            "curr_val_loss: 0.16270877420902252 epoch: 7 best_loss 0.16270877420902252 best_epoch 6\n",
            "Epoch: 08 |Loss:0.18275585770606995\n",
            "curr_val_loss: 0.18550977110862732 epoch: 8 best_loss 0.16270877420902252 best_epoch 6\n",
            "Epoch: 09 |Loss:0.17152433330193162\n",
            "curr_val_loss: 0.17932920157909393 epoch: 9 best_loss 0.16270877420902252 best_epoch 6\n",
            "Epoch: 10 |Loss:0.1800962295383215\n",
            "curr_val_loss: 0.1532340794801712 epoch: 10 best_loss 0.1532340794801712 best_epoch 9\n",
            "Epoch: 11 |Loss:0.17766854027286172\n",
            "curr_val_loss: 0.1474323570728302 epoch: 11 best_loss 0.1474323570728302 best_epoch 10\n",
            "Epoch: 12 |Loss:0.17618023045361042\n",
            "curr_val_loss: 0.16911235451698303 epoch: 12 best_loss 0.1474323570728302 best_epoch 10\n",
            "Epoch: 13 |Loss:0.16034484468400478\n",
            "curr_val_loss: 0.16092796623706818 epoch: 13 best_loss 0.1474323570728302 best_epoch 10\n",
            "Epoch: 14 |Loss:0.16173164825886488\n",
            "curr_val_loss: 0.1454399973154068 epoch: 14 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 15 |Loss:0.16328364447690547\n",
            "curr_val_loss: 0.1564626842737198 epoch: 15 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 16 |Loss:0.16347562987357378\n",
            "curr_val_loss: 0.15318360924720764 epoch: 16 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 17 |Loss:0.16868484299629927\n",
            "curr_val_loss: 0.1544196754693985 epoch: 17 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 18 |Loss:0.22114312089979649\n",
            "curr_val_loss: 0.2113034874200821 epoch: 18 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 19 |Loss:0.1774887265637517\n",
            "curr_val_loss: 0.19978560507297516 epoch: 19 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 20 |Loss:0.19723221473395824\n",
            "curr_val_loss: 0.16621704399585724 epoch: 20 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 21 |Loss:0.17170380055904388\n",
            "curr_val_loss: 0.20126399397850037 epoch: 21 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 22 |Loss:0.19458941463381052\n",
            "curr_val_loss: 0.18383890390396118 epoch: 22 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 23 |Loss:0.19391209073364735\n",
            "curr_val_loss: 0.15098395943641663 epoch: 23 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 24 |Loss:0.16736910166218877\n",
            "curr_val_loss: 0.16072800755500793 epoch: 24 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 25 |Loss:0.17126603703945875\n",
            "curr_val_loss: 0.16234569251537323 epoch: 25 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 26 |Loss:0.17008237447589636\n",
            "curr_val_loss: 0.2765340507030487 epoch: 26 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 27 |Loss:0.19948910921812057\n",
            "curr_val_loss: 0.1773306131362915 epoch: 27 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 28 |Loss:0.17376252729445696\n",
            "curr_val_loss: 0.20794010162353516 epoch: 28 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 29 |Loss:0.2401431631296873\n",
            "curr_val_loss: 0.18753252923488617 epoch: 29 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 30 |Loss:0.2351798703894019\n",
            "curr_val_loss: 0.17182545363903046 epoch: 30 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 31 |Loss:0.2036594543606043\n",
            "curr_val_loss: 0.1647351235151291 epoch: 31 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 32 |Loss:0.17943327222019434\n",
            "curr_val_loss: 0.15572398900985718 epoch: 32 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 33 |Loss:0.16224008798599243\n",
            "curr_val_loss: 0.15471407771110535 epoch: 33 best_loss 0.1454399973154068 best_epoch 13\n",
            "Epoch: 34 |Loss:0.15266178175807\n",
            "curr_val_loss: 0.13867349922657013 epoch: 34 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 35 |Loss:0.16399264801293612\n",
            "curr_val_loss: 0.1396852284669876 epoch: 35 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 36 |Loss:0.15627457201480865\n",
            "curr_val_loss: 0.14479567110538483 epoch: 36 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 37 |Loss:0.15137651842087507\n",
            "curr_val_loss: 0.1386738419532776 epoch: 37 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 38 |Loss:0.1532503440976143\n",
            "curr_val_loss: 0.13981442153453827 epoch: 38 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 39 |Loss:0.1777206975966692\n",
            "curr_val_loss: 0.14765024185180664 epoch: 39 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 40 |Loss:0.20391174126416445\n",
            "curr_val_loss: 0.15735988318920135 epoch: 40 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 41 |Loss:0.1563415015116334\n",
            "curr_val_loss: 0.1444724202156067 epoch: 41 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 42 |Loss:0.1512673683464527\n",
            "curr_val_loss: 0.1641790270805359 epoch: 42 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 43 |Loss:0.17291706707328558\n",
            "curr_val_loss: 0.14194540679454803 epoch: 43 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 44 |Loss:0.16203503590077162\n",
            "curr_val_loss: 0.15001985430717468 epoch: 44 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 45 |Loss:0.17325688526034355\n",
            "curr_val_loss: 0.14257150888442993 epoch: 45 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 46 |Loss:0.17104075383394957\n",
            "curr_val_loss: 0.1686640828847885 epoch: 46 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 47 |Loss:0.18575373757630587\n",
            "curr_val_loss: 0.17720714211463928 epoch: 47 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 48 |Loss:0.16882966831326485\n",
            "curr_val_loss: 0.1959686279296875 epoch: 48 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 49 |Loss:0.15443557687103748\n",
            "curr_val_loss: 0.14358709752559662 epoch: 49 best_loss 0.13867349922657013 best_epoch 33\n",
            "Epoch: 50 |Loss:0.14926588907837868\n",
            "curr_val_loss: 0.15333060920238495 epoch: 50 best_loss 0.13867349922657013 best_epoch 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpVoQ_yhAWqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice(pred, target):\n",
        "    \"\"\"This definition generalize to real valued pred and target vector.\n",
        "This should be differentiable.\n",
        "    pred: tensor with first dimension as batch\n",
        "    target: tensor with first dimension as batch\n",
        "    \"\"\"\n",
        "\n",
        "    smooth = 1.\n",
        "\n",
        "    iflat = pred.contiguous().view(-1)\n",
        "    tflat = target.contiguous().view(-1)\n",
        "    intersection = (iflat * tflat).sum()\n",
        "\n",
        "    A_sum = torch.sum(tflat * iflat)\n",
        "    B_sum = torch.sum(tflat * tflat)\n",
        "    \n",
        "    return (2. * intersection + smooth) / (A_sum + B_sum + smooth) \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8u3EfBoOLXX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "182e750e-1b13-4c67-faa3-eeb296a61a7b"
      },
      "source": [
        "net.load_state_dict(torch.load('best_model.pt'))\n",
        "dice_acc=0\n",
        "for inputs,actual in validloader:\n",
        "    inputs = inputs.to(device)\n",
        "    actual = actual.to(device)\n",
        "    #print(inputs.size())\n",
        "    logit = net(inputs)\n",
        "    pred = logit.argmax(dim=1)\n",
        "    \n",
        "    dice_ = dice(pred, actual)\n",
        "    dice_acc += dice_\n",
        "print (dice_acc/len(validloader))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9591, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ5UCwsqWkuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "5a7d3b23-4998-4f3b-f4a1-22ecba538b3b"
      },
      "source": [
        "dice_acc=0\n",
        "base_dir = 'drive/My Drive/Dataset/Amazon_Forest/Test_masks'\n",
        "for inputs,filename_list in testloader:\n",
        "    inputs = inputs.to(device)\n",
        "    logit = net(inputs)\n",
        "    pred = logit.argmax(dim=1)\n",
        "    for i in range (inputs.size()[0]):\n",
        "        matplotlib.image.imsave(base_dir+'/'+filename_list[i]+'png', pred[i].cpu().numpy())\n",
        "    print(filename_list)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('10.', '11.')\n",
            "('1.', '8.')\n",
            "('14.', '13.')\n",
            "('9.', '3.')\n",
            "('5.', '12.')\n",
            "('2.', '4.')\n",
            "('0.', '6.')\n",
            "('7.',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLgei9dDxi1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "test_img =glob('drive/My Drive/Dataset/Amazon_Forest/Test_masks/**.png')\n",
        "for i in range (len(test_img)):\n",
        "    test_im = Image.open(test_img[i])\n",
        "    #print(test_im.size)\n",
        "    re_testim = test_im.resize((512,512), Image.NEAREST)\n",
        "    \n",
        "    #print(re_testim.size)\n",
        "    matplotlib.image.imsave('drive/My Drive/Dataset/Amazon_Forest/Test_masks_orig' + '/'+os.path.basename(test_img[i]), np.array(re_testim))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgqDbV5Y5kAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}